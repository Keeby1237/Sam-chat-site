<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Debuggable ChatBot</title>
  <style>
    /* ... [Keep existing styles from previous version] ... */
    .error-details {
      background: #ffebee;
      color: #c62828;
      padding: 10px;
      border-radius: 4px;
      margin: 10px;
      font-size: 12px;
      max-height: 100px;
      overflow-y: auto;
    }
  </style>
</head>
<body>
  <div class="loading" id="loading">
    <div>Loading model...</div>
    <div class="progress-text"></div>
  </div>
  
  <div class="chat-container hidden" id="chatContainer">
    <div class="chat-history" id="chatHistory"></div>
    <div class="input-area">
      <input type="text" id="userInput" placeholder="Type your message...">
      <button onclick="sendMessage()">Send</button>
    </div>
  </div>

  <div class="hidden" id="errorContainer">
    <div style="color: red; padding: 20px;">
      <p>Failed to load model</p>
      <div class="error-details" id="errorDetails"></div>
      <button onclick="window.location.reload()">Try Again</button>
    </div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/ @xenova/transformers@2.14.0/dist/transformers.min.js"></script>
  <script>
    const MODEL_NAME = 'Xenova/gpt2-quantized'; // Change to your model
    let pipelineInstance;
    let isLoading = true;

    async function initializeModel() {
      try {
        // Environment checks
        if (typeof WebAssembly === 'undefined') {
          throw new Error('WebAssembly not supported');
        }
        if (!window.isSecureContext) {
          throw new Error('Requires HTTPS or localhost');
        }

        // Model loading with progress
        const progressElement = document.querySelector('#loading .progress-text');
        pipelineInstance = await pipeline('text-generation', MODEL_NAME, {
          quantized: true,
          max_length: 100,
          progress_callback: (progress) => {
            progressElement.textContent = `Loading: ${Math.round(progress * 100)}%`;
          }
        });

        document.getElementById('loading').classList.add('hidden');
        document.getElementById('chatContainer').classList.remove('hidden');
        isLoading = false;
      } catch (error) {
        const errorDetails = document.getElementById('errorDetails');
        errorDetails.textContent = `Error: ${error.message}`;
        console.error('Full error:', error);
        
        document.getElementById('loading').classList.add('hidden');
        document.getElementById('errorContainer').classList.remove('hidden');
      }
    }

    async function sendMessage() {
      if (isLoading) return;

      const input = document.getElementById('userInput').value.trim();
      if (!input) return;

      // Add user message
      addMessage(input, 'user-msg');
      document.getElementById('userInput').value = '';

      // Add loading indicator
      const botMessage = addMessage('...', 'bot-msg');
      
      try {
        const result = await pipelineInstance(input, {
          max_new_tokens: 50,
          do_sample: true
        });
        
        botMessage.textContent = result[0].generated_text;
      } catch (error) {
        botMessage.textContent = 'Error generating response';
        const errorDetails = document.createElement('div');
        errorDetails.className = 'error-details';
        errorDetails.textContent = `Inference Error: ${error.message}`;
        botMessage.appendChild(errorDetails);
        console.error('Inference error:', error);
      }
    }

    function addMessage(text, className) {
      const message = document.createElement('div');
      message.className = `message ${className}`;
      message.textContent = text;
      document.getElementById('chatHistory').appendChild(message);
      document.getElementById('chatHistory').scrollTop = 
        document.getElementById('chatHistory').scrollHeight;
      return message;
    }

    initializeModel();
  </script>
</body>
</html>
